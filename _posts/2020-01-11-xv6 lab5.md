---
layout: post
title:  "6.828 Lab 5: File system, Spawn and Shell"
date:   2020-01-11 17:12:01 +0800
categories: [Tech]
tags:
  - xv6
  - OS
---

>本文为原创

## 磁盘上的文件系统结构

大多数UNIX文件系统将可用磁盘空间分为两种主要区域类型：inode区域和数据区域。 UNIX文件系统为文件系统中的每个文件分配一个索引节点。文件的inode包含有关文件的关键元数据，例如其stat属性和指向其数据块的指针。数据区域被分成许多数据块（通常为8KB或更大），文件系统在其中存储文件数据和目录元数据。目录条目包含文件名和指向inode的指针。如果文件系统中的多个目录条目引用该文件的inode，则该文件被称为`hard-linked`。由于我们的文件系统将不支持硬链接，因此我们不需要这种间接连接，因此可以简化以下操作：我们的文件系统不使用索引节点，而只会存储文件（或子目录）的（唯一的）目录条目中描述所有内容。

文件和目录在逻辑上都由一系列数据块组成，这些数据块可能分散在整个磁盘上，就像环境的虚拟地址空间的页面可以分散在整个物理内存中一样。文件系统环境隐藏了块布局的细节，提供了用于在文件内任意位置读取和写入字节序列的接口。文件系统环境在内部处理对目录的所有修改，这是执行诸如创建和删除文件之类的操作的一部分。我们的文件系统确实允许用户环境直接读取目录元数据（例如，通过`read`），这意味着用户环境可以自己执行目录扫描操作（例如，执行`ls`程序），而不必依赖于对文件系统的特殊调用。它使得在不改变应用程序或者重新编译应用程序的情况下，很难更改文件系统的内部布局，这是目录扫描方法的缺点，也是大多数现代UNIX的变体不鼓励这样做的原因。

### 扇区和块

大多数磁盘无法以字节为单位执行读取和写入，而是以扇区为单位执行读取和写入。在JOS中，每个扇区均为512字节。文件系统实际上以块为单位分配和使用磁盘存储。注意两个术语之间的区别：扇区大小是磁盘硬件的属性，而块大小是使用磁盘的操作系统的一个方面。文件系统的块大小必须是磁盘的扇区大小的倍数。

UNIX xv6文件系统使用512字节的块大小，与磁盘的扇区大小相同。因为存储空间变得便宜得多了，并且以较大的粒度管理存储更加有效，所以大多数现代文件系统使用更大的块大小。我们的文件系统将使用4096字节的块大小，可以方便地匹配处理器的页面大小。

### 超级块

文件系统通常在磁盘的`易于查找的`位置（例如最开始或结尾）保留某些块，以保存描述整个文件系统属性（例如块大小）的元数据，磁盘大小，查找根目录所需的任何元数据，上次安装文件系统的时间，上次检查文件系统的错误的时间等等。这些特殊的块称为超级块。

我们的文件系统将只有一个超级块，该超级块将始终位于磁盘上的块1中。其布局由`inc/fs.h`中的`struct Super`定义。块0通常被保留以容纳引导加载程序和分区表，因此文件系统通常不使用第一个磁盘块。许多`实际的`文件系统维护了多个超级块，这些超级块存放在磁盘的多个间隔较大的区域，存放着相同的数据。因此，如果其中一个损坏或磁盘在该区域中出现介质错误，仍可以找到其他超级块并将其用于访问文件系统。

![]({{ '/assets/images/posts/2020-01-11-xv6 lab5/01.png' | prepend: site.baseurl}})

### 文件元数据

`inc/fs.h`中的`struct File`描述我们的文件系统中的元数据的布局。此元数据包括文件的名称，大小，类型（常规文件或目录），以及指向组成文件的块的指针。如上所述，我们没有inode，因此此元数据存储在磁盘上的目录条目中。与大多数的文件系统不同，为简单起见，我们将使用一种`File`结构来表示文件元数据，因为它同时出现在磁盘和内存中。

`struct File`中的`f_direct`数组包含用于存储文件的前10个（NDIRECT）块的块号的空间，我们将其称为文件的直接块。对于大小不超过10 * 4096 = 40KB的小文件，这意味着该文件所有块的块号将直接适合于File结构本身。但是，对于较大的文件，我们需要一个地方来容纳文件的其余块编号。因此，对于任何大于40KB的文件，我们分配一个额外的磁盘块，称为文件的间接块，以容纳4096/4 = 1024个额外的块号。因此，我们的文件系统允许文件的大小最大为1034块，刚好超过4M字节。为了支持更大的文件，`实际`文件系统通常还支持双重和三重间接块。

![]({{ '/assets/images/posts/2020-01-11-xv6 lab5/02.png' | prepend: site.baseurl}})

### 目录文件与普通文件

我们文件系统中的`File`结构可以代表常规文件或目录； 这两种类型的文件可以通过`文件`结构中的`type`字段来区分。文件系统以完全相同的方式管理普通文件和目录文件，只是它根本不解释与普通文件相关联的数据块的内容，而文件系统将目录文件的内容解释为一系列描述目录中文件和子目录的`File`结构。

我们文件系统中的超级块包含一个`File`结构（`struct Super`中的根字段），其中包含文件系统根目录的元数据。该目录文件的内容是一系列`File`结构，描述了位于文件系统根目录中的文件和目录。根目录中的任何子目录都可能包含更多表示子子目录的File结构，依此类推。

## 磁盘访问

操作系统中的文件系统环境需要能够访问磁盘，但是我们尚未在内核中实现任何磁盘访问功能。我们没有采取将IDE磁盘驱动程序以及允许文件系统访问内核的系统调用添加到内核的这种常规`整体`操作系统策略，而是将IDE磁盘驱动程序实现为用户级文件系统环境的一部分。我们仍然需要稍微修改内核，以便进行设置，方便文件系统环境实现磁盘访问本身所需的特权。

只要我们依靠轮询，以及基于`编程I/O`（PIO）的磁盘访问并且不使用磁盘中断，就可以轻松的在用户空间中实现磁盘访问。也可以在用户模式下实现中断驱动设备的驱动程序（例如L3和L4内核执行此操作），但由于内核必须现场中断设备并将其分派到正确的用户模式环境，因此更加困难。

x86处理器使用EFLAGS寄存器中的IOPL位来确定是否允许保护模式代码执行特殊的设备I/O指令，例如IN和OUT指令。由于我们需要访问的所有IDE磁盘寄存器都位于x86的`I/O`空间中，而不是位于内存映射中，因此，我们唯一需要做的就是为文件系统环境赋予`I/O特权`。允许文件系统访问这些寄存器。实际上，EFLAGS寄存器中的IOPL位为内核提供了一种简单的"all-or-nothing"方法，用于控制用户模式代码是否可以访问I/O空间。在我们的情况下，我们希望文件系统环境能够访问I/O空间，但是我们根本不希望任何其他环境能够访问I/O空间。

### Exercise 1

`i386_init`通过将`ENV_TYPE_FS`类型传递给你的环境创建函数`env_create`来标识文件系统环境。在`env.c`中修改`env_create`，以便它赋予文件系统环境I/O特权，但绝不将该特权赋予任何其他环境。

`kern/env.c env_create`的代码如下：

```c
void
env_create(uint8_t *binary, enum EnvType type)
{
    // LAB 3: Your code here.
    struct Env *e;
    int r = env_alloc(&e, 0);
    if (r)
        panic("env_alloc: %e", r);
    load_icode(e, binary);
    e->env_type = type;

    // If this is the file server (type == ENV_TYPE_FS) give it I/O privileges.
    // LAB 5: Your code here.
    if(type == ENV_TYPE_FS)
        e->env_tf.tf_eflags |= FL_IOPL_MASK;

}
```

确保可以启动文件环境而不会引起`General Protection`错误。你应该能通过`fs i/o`测试。

### Question 1

当你随后从一种环境切换到另一种环境时，是否还需要执行其他操作以确保正确保存和还原此I/O特权设置？为什么？

答案是不需要，因为切换环境需要保存当前环境的硬件上下文并且恢复下一个环境的硬件上下文。

请注意，本实验中的`GNUmakefile`文件将QEMU设置为与以前一样，将文件`obj/kern/kernel.img`用作磁盘0（通常在`DOS/Windows`下为`Drive C`）的映像，并使用（新）文件`obj/fs/fs.img`作为磁盘1（`Drive D`）的​​映像。在本实验中，我们的文件系统只能接触磁盘1；磁盘0仅用于引导内核。如果想以某种方式损坏任何一个磁盘映像，则只需键入以下命令，即可将它们都重置为其“原始”版本：

```bash
rm obj/kern/kernel.img obj/fs/fs.img
make
```

或通过执行以下操作：

```bash
make clean
make
```

## 块缓存

在我们的文件系统中，我们将借助处理器的虚拟内存系统实现一个简单的`buffer cache`（实际上只是一个块缓存）。块缓存的代码在`fs/bc.c`中。

我们的文件系统将只能处理3GB或更小的磁盘。我们在文件系统环境的地址空间为磁盘的`内存映射`保留了固定的3GB区域，从0x10000000（`DISKMAP`）到0xD0000000（`DISKMAP + DISKMAX`）。例如，磁盘块0映射到虚拟地址0x10000000，磁盘块1映射到虚拟地址0x10001000，依此类推。`fs/bc.c`中的`diskaddr`函数实现了从磁盘块号到虚拟地址的转换（以及一些完整性检查）。

由于我们的文件系统环境具有自己的虚拟地址空间，而与系统中其他的环境的虚拟地址空间无关，并且文件系统环境唯一需要做的就是实现文件访问，因此以这种方式保留大多数文件系统环境的地址空间是合理的。由于现代磁盘大于3GB，因此在32位计算机上执行实际文件系统会很尴尬。在具有64位地址空间的计算机上，这种缓冲区高速缓存管理方法可能仍然是合理的。

当然，将整个磁盘读入内存将花费很长时间，因此，我们将实现一种需求分页的形式，其中我们仅在磁盘映射区域中分配页面，并响应页面错误而从磁盘中读取相应的块。该区域中的，这样，我们可以假装整个磁盘都在内存中。

### Exercise 2

在`fs/bc.c`中实现`bc_pgfault`和`flush_block`函数。`bc_pgfault`是一个页面错误处理程序，就像你在上一个实验中为实现写时复制实现的页面处理程序一样，不同之处在于`bc_pgfault`的工作是响应页面错误并从磁盘加载页面。编写此代码时，请记住，（1）`addr`可能未与块边界对齐，并且（2）`ide_read`是以扇区为单位操作而不是以块为单位操作。

必要时，`flush_block`函数应将一个块写入到磁盘。如果该块甚至不在块缓存中（即页面未映射）或它没有设置脏位，则`flush_block`不应执行任何操作。我们将使用VM硬件来跟踪上一次对磁盘的操作是否修改了磁盘块。要查看某个块是否需要写入，我们可以看看是否在uvpt条目中设置了`PTE_D` `dirty`位。 （PTE_D位由处理器根据对该页面的写入进行设置；请参见386参考手册[第5章](http://pdos.csail.mit.edu/6.828/2011/readings/i386/s05_02.htm)中的5.2.4.3。）将块写入磁盘后，`flush_block`应使用`sys_page_map`清除`PTE_D`位。

·fs/bc.c bc_pgfault`的代码如下：

```c
    // LAB 5: you code here:
    addr = (void*) ROUNDDOWN(addr, PGSIZE);
    if((r = sys_page_alloc(0, addr, PTE_U | PTE_W | PTE_P)) < 0)
        panic("In bc_pgfault, sys_page_alloc: %e", r);
    if((r = ide_read(blockno * BLKSECTS, addr, BLKSECTS)) < 0)
        panic("In bc_pgfault, ide_read: %e", r);
```

`fs/bc.c flush_block`的代码如下：

```c
void
flush_block(void *addr)
{
    uint32_t blockno = ((uint32_t)addr - DISKMAP) / BLKSIZE;

    if (addr < (void*)DISKMAP || addr >= (void*)(DISKMAP + DISKSIZE))
        panic("flush_block of bad va %08x", addr);

    // LAB 5: Your code here.
    //panic("flush_block not implemented");
    addr = ROUNDDOWN(addr, PGSIZE);
    if(va_is_mapped(addr) == false || va_is_dirty(addr) == false)
        return;
    int r;
    if((r = ide_write(blockno * BLKSECTS, addr, BLKSECTS)) < 0)
        panic("In flush_block, ide_write: %e", r);
    if ((r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] & PTE_SYSCALL)) < 0)//清除PTE_D
        panic("In flush_block, sys_page_map: %e", r);

}
```

使用`make grade`测试你的代码。你的代码应通过`check_bc`，`check_super`和`check_bitmap`。

`fs/fs.c`中的`fs_init`函数是例子，告诉我们如何使用块缓存。初始化块高速缓存后，它仅将指针存储到全局变量`super`中的磁盘映射区域中。此后，我们可以简单地从`super`中读取它们，就像它们在内存中一样，并且页面错误处理程序将根据需要从磁盘中读取它们。

## The Block Bitmap

在`fs_init`设置了`bitmap`指针之后，我们可以将`bitmap`视为位的打包数组，磁盘上每个块一个。参见，例如，`block_is_free`，其仅检查在位图中是否将给定块标记为空闲。

### Exercise 3

使用`free_block`作为模型在`fs/fs.c`中实现`alloc_block`，后者应在位图中找到可用的磁盘块，将其标记为已使用，然后返回该块的编号。分配块时，应立即使用`flush_block`将更改后的位图块刷新到磁盘，以帮助文件系统保持一致。

```c
// 在位图上搜索空闲块并分配它。分配块时，请立即将更改的位图块刷新到磁盘。
// Return block number allocated on success,
// -E_NO_DISK if we are out of blocks.
//
// Hint: use free_block as an example for manipulating the bitmap.
int
alloc_block(void)
{
    // 位图由一个或多个块组成。单个位图块包含BLKBITSIZE个位。磁盘中总共有super-> s_nblocks个块。
    // LAB 5: Your code here.
    for(int i = 3; i < super->s_nblocks; i ++) {
        if(block_is_free(i)) {
            bitmap[i/32] &= ~(1 << (i % 32)); //bitmap的位，1代表free，0代表被使用
            flush_block(bitmap);
            return i;
        }
    }

    return -E_NO_DISK;
}
```

使用`make grade`测试你的代码。你的代码现在应该能通过`alloc_block`。

## 文件操作

我们在`fs/fs.c`中提供了各种功能，以实现解释和管理文件结构，扫描和管理目录文件条目以及从根目录遍历文件系统以解析绝对地址所需的基本功能。通读`fs/fs.c`中的所有代码，并确保在继续操作之前了解每个函数的功能。

`walk_path`函数，通过传进来的path的路径名，找到文件和目录，将文件存储在pf中，目录存储在pdir中，文件名或者目录名存放在lastelem中。

`dir_alloc_file`函数，将file存放在dir中，都是File结构体。

```c
struct File {
    char f_name[MAXNAMELEN];    // 文件名
    off_t f_size;               // 文件大小（以字节为单位）
    uint32_t f_type;            // 文件类型

    // Block pointers.
    // 如果一个块的分配值为！= 0，则分配该块。
    uint32_t f_direct[NDIRECT]; // direct blocks
    uint32_t f_indirect;        // indirect block
    // 填充字符
    // Pad out to 256 bytes; must do arithmetic in case we're compiling fsformat on a 64-bit machine.
    uint8_t f_pad[256 - MAXNAMELEN - 8 - 4*NDIRECT - 4];
} __attribute__((packed));      // 仅在某些64位计算机上需要
```

### Exercise 4

实现`file_block_walk`和`file_get_block`。`file_block_walk`从文件中的块偏移量映射到`struct File`或间接块中指向这块的指针，类似于`pgdir_walk`对页表所做的操作。`file_get_block`更进一步，并映射到实际的磁盘块，并在必要时分配一个新的磁盘块。

file_block_walk的代码如下：

```c
// 在文件“f”中找到“filebno”对应的磁盘块号。
// 将“*ppdiskbno”设置为指向对应的磁盘块号。
// 该插槽将是f->f_direct[]条目之一，或者是间接块中的条目。
// 当设置了'alloc'时，该函数将在必要时分配一个间接块。
//
// Returns:
//  0 on success (but note that *ppdiskbno might equal 0).
//  -E_NOT_FOUND if the function needed to allocate an indirect block, but
//      alloc was 0.
//  -E_NO_DISK if there's no space on the disk for an indirect block.
//  -E_INVAL if filebno is out of range (it's >= NDIRECT + NINDIRECT).
//
// Analogy: This is like pgdir_walk for files.
// Hint: Don't forget to clear any block you allocate.
static int
file_block_walk(struct File *f, uint32_t filebno, uint32_t **ppdiskbno, bool alloc)
{
    // LAB 5: Your code here.
    // panic("file_block_walk not implemented");
    if(filebno >= NDIRECT + NINDIRECT)
        return -E_INVAL;

    int bn; // 块号
    uint32_t *indirects_addr = NULL;
    if (filebno < NDIRECT) {
        *ppdiskbno = &(f->f_direct[filebno]);
    } else {
        if (f->f_indirect) {
            indirects_addr = diskaddr(f->f_indirect);// f_indirect存放间接块的地址，该块存放文件内容存放的块号
        } else {
            if (!alloc)
                return -E_NOT_FOUND;
            if ((bn = alloc_block()) < 0)
                return bn;
            f->f_indirect = bn;
            indirects_addr = diskaddr(bn);
            // flush_block(indirects_addr);
        }
        *ppdiskbno = &(indirects_addr[filebno - NDIRECT]);
    }
    return 0;
}
```

file_get_block函数代码如下：

```c
// 将*blk设置为将映射文件'f'的第filebno块的内存地址。
//
// Returns 0 on success, < 0 on error.  Errors are:
//  -E_NO_DISK if a block needed to be allocated but the disk is full.
//  -E_INVAL if filebno is out of range.
//
// Hint: Use file_block_walk and alloc_block.
int
file_get_block(struct File *f, uint32_t filebno, char **blk)
{
    // LAB 5: Your code here.
    // panic("file_get_block not implemented");
    uint32_t* ppdiskbno;
    int r;
    if((r = file_block_walk(f, filebno, &ppdiskbno, 1)) < 0)
        return r;

    if((*ppdiskbno) == 0)
    {
        r = alloc_block();
        if(r < 0)
            return r;
        else
            *ppdiskbno = r;
    }
    *blk = (char*)diskaddr(*ppdiskbno);
    flush_block(*blk);
    return 0;
}
```

使用`make grade`测试你的代码。你的代码应通过`file_open`，`file_get_block`，`file_flush/file_truncated/file rewrite`和`testfile`。

`file_block_walk`和`file_get_block`是文件系统的关键部分。

## 文件系统接口

现在我们已经在文件系统环境本身中具有必要的功能，我们必须使它可以被希望使用文件系统的其他环境访问。由于其他环境无法直接在文件系统环境中调用函数，因此我们将通过基于JOS的IPC机制构建的远程程序调用或RPC（抽象）公开对文件系统环境的访问。在图形上，这是对文件系统服务器的调用（例如，读取）的样子

```text

      Regular env           FS env
   +---------------+   +---------------+
   |      read     |   |   file_read   |
   |   (lib/fd.c)  |   |   (fs/fs.c)   |
...|.......|.......|...|.......^.......|...............
   |       v       |   |       |       | RPC mechanism
   |  devfile_read |   |  serve_read   |
   |  (lib/file.c) |   |  (fs/serv.c)  |
   |       |       |   |       ^       |
   |       v       |   |       |       |
   |     fsipc     |   |     serve     |
   |  (lib/file.c) |   |  (fs/serv.c)  |
   |       |       |   |       ^       |
   |       v       |   |       |       |
   |   ipc_send    |   |   ipc_recv    |
   |       |       |   |       ^       |
   +-------|-------+   +-------|-------+
           |                   |
           +-------------------+
```

虚线下方的所有内容仅是将读取请求从常规环境传送到文件系统环境的机制。从一开始，`read`（我们提供的）就可以在任何文件描述符上工作，并简单地分派到适当的设备读取功能，这就是`devfile_read`（我们可以有更多设备类型，例如管道）。`devfile_read`实现专门针对磁盘文件的读取。`lib/file.c`中的此函数和其他`devfile_*`函数实现了FS操作的客户端，并且所有工作均以大致相同的方式进行，将参数捆绑在请求结构中，调用`fsipc`发送IPC请求，然后解包并返回结果。`fsipc`函数仅处理将请求发送到服务器并接收答复的常见细节。

文件系统服务器代码可以在`fs/serv.c`中找到。它循环执行服务功能，无休止地通过IPC接收请求，将该请求分派到适当的处理程序，然后通过IPC发回结果。在示例中，`serve`将分派到`serve_read`，后者将处理IPC的详细信息，例如解压缩请求结构并最终调用`file_read`来实际执行文件读取。

回想一下，JOS的IPC机制使环境可以发送单个32位的值，并可以选择共享页面。要将请求从客户端发送到服务器，我们使用32位的值作为请求类型（对文件系统服务器RPC进行编号，就像对系统调用进行编号一样），并将请求的参数存储在IPC共享的页面的`union Fsipc`上。在客户端，我们总是在`fsipcbuf`的共享页面上传输数据；在服务器端，我们将传入的请求页面映射到`fsreq`（`0x0ffff000`）。

服务器还通过IPC发回响应。我们使用32位数字作为函数的返回码。对于大多数RPC，这就是它们返回的全部。`FSREQ_READ`和`FSREQ_STAT`也返回数据，它们只是将数据写入客户端发送的请求的页面。因为客户端首先将其与文件系统服务器共享页面，所以无需在响应IPC中发送此页面。同样，在响应中，`FSREQ_OPEN`与客户端共享一个新的`Fd page`。我们将很快返回文件描述符页面。

### Exercise 5

在`fs/serv.c`中实现`serve_read`。

`serve_read`的繁重工作将由`fs/fs.c`中已经实现的`file_read`来完成（反过来，这只是对`file_get_block`的一堆调用）。`serve_read`只需提供RPC接口即可读取文件。查看`serve_set_size`中的注释和代码，以大致了解服务器功能的结构。

文件系统服务器为每个打开的文件维护了三个结构。

1. 磁盘上的`struct File`被映射到映射磁盘的内存部分。该内存是文件服务器私有的。

2. 每个打开的文件也都有一个`struct Fd`，它对应于一个Unix文件描述符。这个`struct Fd`被当作内存的一部分，并且与任何打开文件的环境共享。

3. `struct OpenFile`链接其他两个结构，并且是文件服务器的私有部分。服务器维护所有打开文件的数组，并按`file ID`索引。（最多可以同时打开`MAXOPEN`文件。）客户端使用文件ID与服务器进行通信。文件ID与内核中的环境ID非常相似。使用`openfile_lookup`将文件ID转换为结构`OpenFile`。

```c
// 从ipc->read.req_fileid中的当前查找位置读取最多ipc->read.req_n个字节。
// 在ipc->readRet中将从文件读取的字节返回给调用方，然后更新查找位置。
// 返回成功读取的字节数，如果错误，则返回<0。
int
serve_read(envid_t envid, union Fsipc *ipc)
{
    struct Fsreq_read *req = &ipc->read;
    struct Fsret_read *ret = &ipc->readRet;

    if (debug)
        cprintf("serve_read %08x %08x %08x\n", envid, req->req_fileid, req->req_n);

    // Lab 5: Your code here:
    struct OpenFile *o = NULL;
    int r = openfile_lookup(envid, req->req_fileid, &o);
    if(r < 0)
        return r;

    r = file_read(o->o_file, ret->ret_buf, req->req_n, o->o_fd->fd_offset);
    if(r < 0)
        return r;

    o->o_fd->fd_offset += r;
    return r;
}
```

使用`make grade`测试你的代码。你的代码应通过`serve_open/file_stat/file_close`和`file_read`，得分为70/150。

70分是还需要通过`Protection I/O space: OK (0.9s)`

### Exercise 6

Implement `serve_write` in `fs/serv.c` and `devfile_write` in `lib/file.c`.

```c
// 从当前查找位置开始，将req->req_buf中的req->req_n个字节写入req_fileid，并相应地更新查找位置。
// 如有必要，扩展文件。 返回写入的字节数，如果错误，则返回<0。
int
serve_write(envid_t envid, struct Fsreq_write *req)
{
    if (debug)
        cprintf("serve_write %08x %08x %08x\n", envid, req->req_fileid, req->req_n);

    // LAB 5: Your code here.
    //panic("serve_write not implemented");
    struct OpenFile *o = NULL;
    int r = openfile_lookup(envid, req->req_fileid, &o);
    if(r < 0)
        return r;

    r = file_write(o->o_file, req->req_buf, req->req_n, o->o_fd->fd_offset);
    if(r < 0)
        return r;
    o->o_fd->fd_offset += r;
    return r;
}
```

```c
// Write at most 'n' bytes from 'buf' to 'fd' at the current seek position.
//
// Returns:
//   The number of bytes successfully written.
//   < 0 on error.
static ssize_t
devfile_write(struct Fd *fd, const void *buf, size_t n)
{
    // Make an FSREQ_WRITE request to the file system server.  Be
    // careful: fsipcbuf.write.req_buf is only so large, but
    // remember that write is always allowed to write *fewer*
    // bytes than requested.
    // LAB 5: Your code here
    //panic("devfile_write not implemented");
    fsipcbuf.write.req_fileid = fd->fd_file.id;
    fsipcbuf.write.req_n = n;
    memcpy(fsipcbuf.write.req_buf, buf, n);
    return fsipc(FSREQ_WRITE, NULL); //第二位参数只有在是需要读取数据的时候才设置
}
```

Use `make grade` to test your code. Your code should pass `file_write`, `file_read after file_write`, `open`, and `large file` for a score of 90/150.

在`kern/init.c`下的i386_init()少了一个加锁，应该是在分支合并的时候出了问题

## Spawning Processes

`spawn`的代码（请参阅`lib/spawn.c`）将创建一个新环境，将文件系统中的程序映像加载到其中，然后启动子环境运行该程序。然后，父进程继续独立于子进程继续运行。在UNIX中，`spawn`函数的作用类似于`fork`后的子进程中紧跟的`exec`。

我们实现了`spawn`而不是UNIX风格的`exec`，因为在用户空间中以`exokernel fashion`更容易实现`spawn`，无需内核的帮助。考虑一下要在用户空间中实现`exec`所必须执行的操作，并确保您了解为什么这样做更难。

### Exercise 7

`spawn`依赖于新的系统调用`sys_env_set_trapframe`来初始化新创建的环境的状态。在`kern/syscall.c`中实现`sys_env_set_trapframe`（不要忘记在`syscall()`中调用新的系统调用）。

```c
// Set envid's trap frame to 'tf'.
// tf is modified to make sure that user environments always run at code
// protection level 3 (CPL 3), interrupts enabled, and IOPL of 0.
//
// Returns 0 on success, < 0 on error.  Errors are:
//  -E_BAD_ENV if environment envid doesn't currently exist,
//      or the caller doesn't have permission to change envid.
static int
sys_env_set_trapframe(envid_t envid, struct Trapframe *tf)
{
    // LAB 5: Your code here.
    // Remember to check whether the user has supplied us with a good
    // address!
    struct Env* env = NULL;
    int r = envid2env(envid, &env, 1);
    if(r < 0)
        return r;

    tf->tf_eflags |= FL_IF; //开启中断
    tf->tf_eflags &= ~FL_IOPL_MASK;         //普通进程不能有IO权限
    tf->tf_cs = GD_UT | 3; //设置CPL
    env->env_tf = *tf; //保存栈帧
    return 0;
}
```

添加系统调用

```c
case SYS_env_set_trapframe:
    ret = sys_env_set_trapframe(a1, (struct Trapframe *)a2);
    break;
```

通过在`kern/init.c`中运行`user/spawnhello`程序来测试代码，该程序将尝试从文件系统中生成`/hello`。

使用`make grade`测试代码。

## Sharing library state across fork and spawn

UNIX文件描述符是一个通用概念，还包含管道，控制台I/O等。在JOS中，这些设备类型中的每一个都有对应的`struct Dev`，以及指向实现读/写/等功能的指针。针对该设备类型，`lib/fd.c`在此之上实现了通用的类UNIX的文件描述符接口。每个`struct Fd`都指示其设备类型，并且`lib/fd.c`中的大多数功能只是将操作分派给相应`struct Dev`中的功能。

`lib/fd.c`还在每个应用程序环境的地址空间中维护文件描述符表区域。该区域为应用程序保留一个页面的地址空间（4KB），应用程序可以一次打开的最多`MAXFD`（当前为32个）文件描述符。在任何给定时间，当且仅当使用相应的文件描述符时，才会映射特定的文件描述符表页面。每个文件描述符在从`FILEDATA`开始的区域中还具有一个可选的`data page`，设备可以选择使用它们。

我们希望在`fork`和`spawn`之间共享文件描述符状态，但是文件描述符状态保留在用户空间内存中。现在，在`fork`时，内存将被标记为写时复制，因此状态将被复制而不是共享。（这意味着环境将无法在自身未打开的文件中进行搜索，并且管道将无法在分叉上工作。）在`spawn`时，内存将被留下，根本不会被复制。（有效地，`spawn`生成的环境开始时没有打开的文件描述符。）

我们将更改`fork`以了解某些内存区域已由`library operating system`使用，并且应始终共享。与其在某处硬编码区域列表，不如在页表条目中设置一个未使用的位（就像我们对`fork`中的`PTE_COW`位所做的那样）。

我们在`inc/lib.h`中定义了一个新的`PTE_SHARE`位。该位是Intel和AMD手册中标记为`available for software use`的三个PTE位之一。我们将建立一个约定，如果页表条目设置了该位，则应该在`fork`和`spawn`中将PTE直接从父级复制到子级。请注意，这与将其标记为`写时复制`不同：如第一段所述，我们要确保共享页面更新。

### Exercise 8

在`lib/fork.c`中更改`duppage`以遵循新约定。如果页表项设置了`PTE_SHARE`位，则直接复制映射。（你应该使用`PTE_SYSCALL`而不是`0xfff`来屏蔽页表项中的相关位。`0xfff`也会设置访问的位和脏位。）

duppage修改为如下：

```c
static int
duppage(envid_t envid, unsigned pn)
{
    int r;

    // LAB 4: Your code here.
    uintptr_t* va = (void *) (pn * PGSIZE);
    pte_t pte = uvpt[PGNUM(va)];
    if(!(pte & PTE_P))
        return -1;

    if(pte & PTE_SHARE) { //必须放最前面
        if((r = sys_page_map(0, va, envid, va, PTE_SYSCALL)) < 0)
            panic("Page Map Failed: %e", r);
    } else if((pte & PTE_W) || (pte & PTE_COW)) {
        // 因为envid2env根据envid返回环境，而envid是0时，则返回当前环境，所以使用0代表当前环境
        // 将当前环境的va地址所在的页复制到envid环境的地址空间va所在的页
        if((r = sys_page_map(0, va, envid, va, PTE_U | PTE_COW | PTE_P)) < 0)
            panic("Page Map Failed: %e", r);
        // 把当前环境的页表权限改变为写时复制
        if((r = sys_page_map(0, va, 0, va, PTE_U | PTE_COW | PTE_P)) < 0)
            panic("Page Map Failed: %e", r);
    } else { // 当va所在的页的没有写权限时，只需要简单复制
        if((r = sys_page_map(0, va, envid, va, PTE_U | PTE_P)) < 0)
            panic("Page Map Failed: %e", r);
    }
    return 0;
}
```

同样，在`lib/spawn.c`中实现`copy_shared_pa​​ges`。它应该遍历当前进程中的所有页表条目（就像`fork`一样），将所有已设置`PTE_SHARE`位的页映射复制到子进程中。

copy_shared_pages的代码如下：

```c
// Copy the mappings for shared pages into the child address space.
static int
copy_shared_pages(envid_t child)
{
    // LAB 5: Your code here.
    uintptr_t addr;
    for (addr = 0; addr < UTOP; addr += PGSIZE) {
        if ((uvpd[PDX(addr)] & PTE_P) && (uvpt[PGNUM(addr)] & PTE_P) &&
                (uvpt[PGNUM(addr)] & PTE_U) && (uvpt[PGNUM(addr)] & PTE_SHARE)) {
            sys_page_map(0, (void*)addr, child, (void*)addr, (uvpt[PGNUM(addr)] & PTE_SYSCALL));
        }
    }
    return 0;
}
```

使用`make run-testpteshare-nox`检查你的代码是否正常运行。你应该看到这样的行：`fork handles PTE_SHARE right`和`spawn handles PTE_SHARE right`。

使用`make run-testfdsharing-nox`检查文件描述符是否正确共享。您应该看到显示`read in child succeeded`和`read in parent succeeded`的行。

### 键盘接口

为了实现shell，我们需要一种输入方式。 QEMU一直在显示我们写入到CGA显示器和串行端口的数据，但是到目前为止，我们仅在内核监视器中才接受输入。在QEMU中，图形窗口中的显示为从键盘到JOS的输入，而在控制台的显示为串行端口上的字符。从实验1开始，`kern/console.c`已经包含了内核监视器使用的键盘和串行驱动程序，但是现在你需要将它们附加到系统的其余部分。

#### Exercise 9

在`kern/trap.c`中，调用`kbd_intr`处理陷阱`IRQ_OFFSET + IRQ_KBD`，并调用`serial_intr`处理陷阱`IRQ_OFFSET + IRQ_SERIAL`。

```c
    // Handle keyboard and serial interrupts.
    // LAB 5: Your code here.
    if(tf->tf_trapno == IRQ_OFFSET + IRQ_KBD)
    {
        kbd_intr();
        return;
    }
    if(tf->tf_trapno == IRQ_OFFSET + IRQ_SERIAL)
    {
        serial_intr();
        return;
    }
```

我们在`lib/console.c`中为你实现了控制台输入/输出文件类型。`kbd_intr`和`serial_intr`用最近读取的输入填充缓冲区，而控制台文件类型消耗缓冲区（默认情况下，除非用户将其重定向，否则控制台文件类型用于`stdin/stdout`）。

通过运行`make run-testkbd`并键入几行来测试代码。系统会在完成线路后回显你的线路。如果两者都可用，请尝试在控制台和图形窗口中键入。

### The Shell

运行`make run-icode`或`make run-icode-nox`。这将运行内核并启动`user/icode`。icode执行init，它将控制台设置为文件描述符0和1（标准输入和标准输出）。然后它将生成sh，shell。应该能够运行以下命令：

```bash
    echo hello world | cat
    cat lorem |cat
    cat lorem |num
    cat lorem |num |num |num |num |num
    lsfd
```

请注意，用户库例程`cprintf`无需使用文件描述符代码即可直接打印到控制台。这对调试很有用，但对管道连接到其他程序却不利。要将输出打印到特定的文件描述符（例如，1，标准输出），请使用`fprintf（1，“ ...”，...）`。`printf（“ ...”，...）`是打印到FD 1的快捷方式。有关示例，请参见`user/lsfd.c`。

#### Exercise 10

Shell不支持I/O重定向。最好运行`sh <script`而不是像上面一样手动输入脚本中的所有命令。将<的I/O重定向添加到`user/sh.c`。

`user/sh.c runcmd`的代码如下：

```c
    // LAB 5: Your code here.
    if ((fd = open(t, O_RDONLY)) < 0) {
        cprintf("open %s for write: %e", t, fd);
        exit();
    }
    if(fd != 0)
    {
        dup(fd, 0);
        close(fd);
    }
    break;
```

通过在shell中键入`sh <script`来测试你的实现

运行`make run-testshell`来测试shell。`testshell`只是将上述命令（也可以在`fs/testshell.sh`中找到）输入到Shell中，然后检查输出是否与`fs/testshell.key`相匹配。

最后一个测试通不过的可以改一下测试脚本的超时时间，哭了
