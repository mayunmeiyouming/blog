---
layout: post
title:  "TCR BERT"
date:   2022-05-30 22:10:01 +0800
categories: [Paper]
tag: 
  - Deep Learning
  - 生物信息
---

> 笔记

tcr bert 和 bert 本身有几乎一样的处理过程

卷积网络在生物序列中进行分类和基序发现拥有很好的能力

TCR-BERT 提取 T 细胞受体氨基酸序列并生成可用于下游任务的连续嵌入。为了预先训练 TCR-BERT，我们首先执行掩蔽氨基酸预测，训练 TCR-BERT 预测掩蔽或隐藏的氨基酸，基于周围的氨基酸，从而学习自然的 TCR的 “语法” 结构。这是在没有 MHC 或 HLA 限制的大量 TRA 和 TRB 序列上完成的，关键是不需要抗原结合亲和力的知识。接下来，我们采用这个模型，并进一步训练它，以预测一组 45 个抗原标签，一个给定的 TRB 氨基酸序列与之结合的抗原。在检查训练前的有效性，并为下游任务选择最佳表示层后，TCR-BERT 可用于各种 TCR 分析，包括预测抗原结合和聚类 TCR。 

在最广泛的训练数据大小范围内，第 8 层最一致地生成最佳 AUPRC（我们的主要评估指标）。